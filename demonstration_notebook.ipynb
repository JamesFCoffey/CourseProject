{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 410: Text Information Systems Course Project\n",
    "# Demonstration Notebook\n",
    "Python implementation of a causal topic modeling paper.\n",
    "\n",
    "This program implements the following paper:\n",
    "<blockquote>\n",
    "    <p>Hyun Duk Kim, Malu Castellanos, Meichun Hsu, ChengXiang Zhai, Thomas Rietz, and Daniel Diermeier. 2013. Mining causal topics in text data: Iterative topic modeling with time series feedback. In Proceedings of the 22nd ACM international conference on information & knowledge management (CIKM 2013). ACM, New York, NY, USA, 885-890. DOI=10.1145/2505515.2505612</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "### Time-Series: Iowa Electronic Markets (IEM)3 2000 Presidential Winner-Takes-All Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contract</th>\n",
       "      <th>Units</th>\n",
       "      <th>$Volume</th>\n",
       "      <th>LowPrice</th>\n",
       "      <th>HighPrice</th>\n",
       "      <th>AvgPrice</th>\n",
       "      <th>LastPrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-05-01</th>\n",
       "      <td>Dem</td>\n",
       "      <td>224</td>\n",
       "      <td>112.043</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-01</th>\n",
       "      <td>Reform</td>\n",
       "      <td>2</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-01</th>\n",
       "      <td>Rep</td>\n",
       "      <td>116</td>\n",
       "      <td>57.95</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-02</th>\n",
       "      <td>Dem</td>\n",
       "      <td>87</td>\n",
       "      <td>44.369</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-02</th>\n",
       "      <td>Reform</td>\n",
       "      <td>50</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-11-09</th>\n",
       "      <td>Reform</td>\n",
       "      <td>2,065</td>\n",
       "      <td>2.062</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-11-09</th>\n",
       "      <td>Rep</td>\n",
       "      <td>10,055</td>\n",
       "      <td>542.973</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-11-10</th>\n",
       "      <td>Dem</td>\n",
       "      <td>3,454</td>\n",
       "      <td>3,328.02</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-11-10</th>\n",
       "      <td>Reform</td>\n",
       "      <td>23</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-11-10</th>\n",
       "      <td>Rep</td>\n",
       "      <td>3,519</td>\n",
       "      <td>148.171</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Contract   Units   $Volume  LowPrice  HighPrice  AvgPrice  \\\n",
       "Date                                                                   \n",
       "2000-05-01      Dem     224   112.043     0.490      0.550     0.500   \n",
       "2000-05-01   Reform       2     0.067     0.019      0.048     0.034   \n",
       "2000-05-01      Rep     116     57.95     0.488      0.501     0.500   \n",
       "2000-05-02      Dem      87    44.369     0.501      0.522     0.510   \n",
       "2000-05-02   Reform      50     0.196     0.003      0.005     0.004   \n",
       "...             ...     ...       ...       ...        ...       ...   \n",
       "2000-11-09   Reform   2,065     2.062     0.000      0.001     0.001   \n",
       "2000-11-09      Rep  10,055   542.973     0.025      0.109     0.054   \n",
       "2000-11-10      Dem   3,454  3,328.02     0.950      0.980     0.964   \n",
       "2000-11-10   Reform      23      0.02     0.000      0.001     0.001   \n",
       "2000-11-10      Rep   3,519   148.171     0.020      0.071     0.042   \n",
       "\n",
       "            LastPrice  \n",
       "Date                   \n",
       "2000-05-01      0.550  \n",
       "2000-05-01      0.019  \n",
       "2000-05-01      0.500  \n",
       "2000-05-02      0.508  \n",
       "2000-05-02      0.003  \n",
       "...               ...  \n",
       "2000-11-09      0.000  \n",
       "2000-11-09      0.050  \n",
       "2000-11-10      0.969  \n",
       "2000-11-10      0.000  \n",
       "2000-11-10      0.031  \n",
       "\n",
       "[576 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pres_market = pd.read_csv(\"./data/PRES00_WTA.csv\", skipinitialspace=True)\n",
    "pres_market = pres_market.set_index(\"Date\")\n",
    "pres_market.index = pd.to_datetime(pres_market.index)\n",
    "pres_market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Series:  American Airlines Group Inc. (AAMRQ) and Apple Inc. (AAPL) Stock Closing Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2000-07-03    26.13\n",
       "2000-07-05    28.38\n",
       "2000-07-06    29.00\n",
       "2000-07-07    29.13\n",
       "2000-07-10    30.00\n",
       "              ...  \n",
       "2001-12-24    21.19\n",
       "2001-12-26    21.57\n",
       "2001-12-27    21.50\n",
       "2001-12-28    22.00\n",
       "2001-12-31    22.30\n",
       "Name: Close, Length: 373, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AAMRQ = pd.read_csv(\"./data/AAMRQ.csv\")\n",
    "AAMRQ = AAMRQ.set_index(\"Date\")\n",
    "AAMRQ.index = pd.to_datetime(AAMRQ.index)\n",
    "AAMRQ_close = AAMRQ[\"Close\"]\n",
    "AAMRQ_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2000-07-03    0.952009\n",
       "2000-07-05    0.921875\n",
       "2000-07-06    0.925223\n",
       "2000-07-07    0.972098\n",
       "2000-07-10    1.020089\n",
       "                ...   \n",
       "2001-12-21    0.375000\n",
       "2001-12-24    0.381429\n",
       "2001-12-26    0.383750\n",
       "2001-12-27    0.394107\n",
       "2001-12-28    0.400536\n",
       "Name: Close, Length: 373, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AAPL = pd.read_csv(\"./data/AAPL.csv\")\n",
    "AAPL = AAPL.set_index(\"Date\")\n",
    "AAPL.index = pd.to_datetime(AAPL.index)\n",
    "AAPL_close = AAPL[\"Close\"]\n",
    "AAPL_close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Corpus: New York Times Annotated Corpus (NYTAC)\n",
    "Do not run this code below. It was to run the original data cleaning steps. Running again will delete the NYTAC in storage. It has been commented out for safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tars = []\n",
    "for root, dirs, files in os.walk(\"./data/nyt_corpus/data\"):\n",
    "    if dirs:\n",
    "        delete = dirs.copy()\n",
    "        delete[:] = [x for x in dirs if x not in ['2000', '2001', '2002', '2003']]\n",
    "        dirs[:] = [x for x in dirs if x in ['2000', '2001', '2002', '2003']]\n",
    "        for name in delete:\n",
    "            subdir = os.path.join(root, name)\n",
    "            with os.scandir(subdir) as it:\n",
    "                for entry in it:\n",
    "                    os.remove(entry)\n",
    "            os.rmdir(subdir)\n",
    "    if files:\n",
    "        if os.path.basename(root) == '2003':\n",
    "            delete = files.copy()\n",
    "            delete = [x for x in files if x not in ['01.tgz', '02.tgz', '03.tgz']]\n",
    "            files[:] = [x for x in files if x in ['01.tgz', '02.tgz', '03.tgz']]\n",
    "            for name in delete:\n",
    "                os.remove(os.path.join(root, name))\n",
    "        for file in files:\n",
    "            tars.append(os.path.join(root, file))\n",
    "\n",
    "for file_path in tars:\n",
    "    tar = tarfile.open(file_path)\n",
    "    tar.extractall(path=os.path.dirname(file_path))\n",
    "    tar.close()\n",
    "    os.remove(file_path)\n",
    "\n",
    "# collect articles for 2000 Presidential Election\n",
    "with os.scandir(\"./data/nyt_corpus/data/2000\") as it:\n",
    "    for entry in it:\n",
    "        if os.path.basename(entry) in ['05', '06', '07', '08', '09', '10']:\n",
    "            shutil.copytree(entry, os.path.join(\"./data/nyt_corpus/data/election/2000\", os.path.basename(entry)))\n",
    "\n",
    "# collect articles for Stock Time Series, AAMRQ vs. AAPL\n",
    "with os.scandir(\"./data/nyt_corpus/data/2000\") as it:\n",
    "    for entry in it:\n",
    "        if os.path.basename(entry) in ['07', '08', '09', '10', '11', '12']:\n",
    "            shutil.copytree(entry, os.path.join(\"./data/nyt_corpus/data/stock/2000\", os.path.basename(entry)))\n",
    "with os.scandir(\"./data/nyt_corpus/data/2001\") as it:\n",
    "    for entry in it:\n",
    "        shutil.copytree(entry, os.path.join(\"./data/nyt_corpus/data/stock/2001\", os.path.basename(entry)))\n",
    "\n",
    "# collect articles for Iraq War\n",
    "with os.scandir(\"./data/nyt_corpus/data/2002\") as it:\n",
    "    for entry in it:\n",
    "        shutil.copytree(entry, os.path.join(\"./data/nyt_corpus/data/war/2002\", os.path.basename(entry)))\n",
    "with os.scandir(\"./data/nyt_corpus/data/2003\") as it:\n",
    "    for entry in it:\n",
    "        if os.path.basename(entry) in ['01', '02', '03']:\n",
    "            shutil.copytree(entry, os.path.join(\"./data/nyt_corpus/data/war/2003\", os.path.basename(entry)))\n",
    "\n",
    "# remove unused directories\n",
    "for year in ['2000', '2001', '2002', '2003']:\n",
    "    shutil.rmtree(os.path.join(\"./data/nyt_corpus/data\", os.path.basename(year)))\n",
    "\n",
    "# initialize list of documents to delete\n",
    "delete = []\n",
    "\n",
    "# delete documents that do not contain \"Bush\" and \"Gore\" or do not contain document bodies\n",
    "for root, dirs, files in os.walk(\"./data/nyt_corpus/data/election\"):\n",
    "    if files:\n",
    "        for name in files:\n",
    "            tree = ET.parse(os.path.join(root, name))\n",
    "            tree_root = tree.getroot()\n",
    "            element = tree_root.find('./body/body.content/block[@class=\"full_text\"]')\n",
    "            if element:\n",
    "                keep = 0\n",
    "                Bush = 0\n",
    "                Gore = 0\n",
    "                for para in element.findall('p'):\n",
    "                    para_list = nltk.word_tokenize(para.text)\n",
    "                    if 'Bush' in para_list:\n",
    "                        Bush = 1\n",
    "                    if 'Gore' in para_list:\n",
    "                        Gore = 1\n",
    "                    keep = Bush * Gore\n",
    "                if not keep:\n",
    "                    delete.append(os.path.join(root, name))\n",
    "            else:\n",
    "                delete.append(os.path.join(root, name))\n",
    "\n",
    "# delete documents that do not contain document bodies\n",
    "for root, dirs, files in os.walk(\"./data/nyt_corpus/data/stock\"):\n",
    "    if files:\n",
    "        for name in files:\n",
    "            tree = ET.parse(os.path.join(root, name))\n",
    "            tree_root = tree.getroot()\n",
    "            element = tree_root.find('./body/body.content/block[@class=\"full_text\"]')\n",
    "            if not element:\n",
    "                delete.append(os.path.join(root, name))\n",
    "\n",
    "# delete documents that do not contain \"Iraq\" or do not contain document bodies\n",
    "for root, dirs, files in os.walk(\"./data/nyt_corpus/data/war\"):\n",
    "    if files:\n",
    "        for name in files:\n",
    "            tree = ET.parse(os.path.join(root, name))\n",
    "            tree_root = tree.getroot()\n",
    "            element = tree_root.find('./body/body.content/block[@class=\"full_text\"]')\n",
    "            if element:\n",
    "                keep = 0\n",
    "                for para in element.findall('p'):\n",
    "                    para_list = nltk.word_tokenize(para.text)\n",
    "                    if 'Iraq' in para_list:\n",
    "                        keep = 1\n",
    "                if not keep:\n",
    "                    delete.append(os.path.join(root, name))\n",
    "            else:\n",
    "                delete.append(os.path.join(root, name))\n",
    "\n",
    "# delete the unneeded documents\n",
    "for name in delete:\n",
    "    os.remove(name)\n",
    "\n",
    "# delete empty directories\n",
    "for root, dirs, files in os.walk(\"./data/nyt_corpus/data\"):\n",
    "    if not dirs and not files:\n",
    "        os.rmdir(root)\n",
    "\n",
    "# consolidate xml files into text files\n",
    "# one text file contains the documents from the date in the file name\n",
    "# documents are stored one document per line\n",
    "for root, dirs, files in os.walk(\"./data/nyt_corpus/data\"):\n",
    "    if files:\n",
    "        yyyy = os.path.basename(os.path.dirname(os.path.dirname(root)))\n",
    "        mm = os.path.basename(os.path.dirname(root))\n",
    "        dd = os.path.basename(root)\n",
    "        file_name = yyyy + \"-\" + mm + \"-\" + dd + \".txt\"\n",
    "        base_folder = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(root))))\n",
    "        directory = os.path.join(\"./data/nyt_corpus/data\", base_folder)\n",
    "        f = open(os.path.join(directory, file_name), \"w\")\n",
    "        for name in files:\n",
    "            tree = ET.parse(os.path.join(root, name))\n",
    "            tree_root = tree.getroot()\n",
    "            element = tree_root.find('./body/body.content/block[@class=\"full_text\"]')\n",
    "            paragraphs = []\n",
    "            for para in element.findall('p'):\n",
    "                paragraphs.append(para.text)\n",
    "            f.write(\" \".join(paragraphs) + \"\\n\")\n",
    "        f.close()\n",
    "\n",
    "# remove unused directories\n",
    "for subdir in [\"election/2000\", \"stock/2000\", \"stock/2001\", \"war/2002\", \"war/2003\"]:\n",
    "    shutil.rmtree(os.path.join(\"./data/nyt_corpus/data\", subdir))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process Data\n",
    "### Time-Series: Iowa Electronic Markets (IEM)3 2000 Presidential Winner-Takes-All Market\n",
    "Follow standard practice in the field and use the “normalized” price of one candidate as a forecast probability of the election outcome:\n",
    "\n",
    "(Gore price)/(Gore price + Bush price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2000-05-01    0.500000\n",
       "2000-05-02    0.507463\n",
       "2000-05-03    0.508492\n",
       "2000-05-04    0.510490\n",
       "2000-05-05    0.519115\n",
       "                ...   \n",
       "2000-11-06    0.270378\n",
       "2000-11-07    0.330986\n",
       "2000-11-08    0.806452\n",
       "2000-11-09    0.945838\n",
       "2000-11-10    0.958250\n",
       "Name: AvgPrice, Length: 192, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gore_price = pres_market.loc[pres_market[\"Contract\"] == \"Dem\"][\"AvgPrice\"]\n",
    "bush_price = pres_market.loc[pres_market[\"Contract\"] == \"Rep\"][\"AvgPrice\"]\n",
    "pres_market_forcprob = gore_price / (gore_price + bush_price)\n",
    "pres_market_forcprob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make data series stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2000-05-02    0.001587\n",
       "2000-05-03    0.003497\n",
       "2000-05-04    0.003884\n",
       "2000-05-05    0.000984\n",
       "2000-05-06    0.001596\n",
       "                ...   \n",
       "2000-11-06    0.029303\n",
       "2000-11-07    0.179776\n",
       "2000-11-08    0.225153\n",
       "2000-11-09    0.209088\n",
       "2000-11-10    0.048531\n",
       "Name: AvgPrice, Length: 191, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pres_market_forcprob = pres_market_forcprob.rolling(3, center=True, min_periods=2).mean()\n",
    "pres_market_forcprob = pres_market_forcprob.diff()[1:]\n",
    "pres_market_forcprob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Series:  American Airlines Group Inc. (AAMRQ) and Apple Inc. (AAPL) Stock Closing Prices\n",
    "Make data series stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2000-07-05    0.581667\n",
       "2000-07-06    1.000000\n",
       "2000-07-07    0.540000\n",
       "2000-07-10    0.146667\n",
       "2000-07-11    0.500000\n",
       "                ...   \n",
       "2001-12-24   -0.026667\n",
       "2001-12-26   -0.130000\n",
       "2001-12-27    0.270000\n",
       "2001-12-28    0.243333\n",
       "2001-12-31    0.216667\n",
       "Name: Close, Length: 372, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AAMRQ_close = AAMRQ_close.rolling(3, center=True, min_periods=2).mean()\n",
    "AAMRQ_close = AAMRQ_close.diff()[1:]\n",
    "AAMRQ_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2000-07-05   -0.003906\n",
       "2000-07-06    0.006696\n",
       "2000-07-07    0.032738\n",
       "2000-07-10    0.030506\n",
       "2000-07-11    0.026414\n",
       "                ...   \n",
       "2001-12-21   -0.001547\n",
       "2001-12-24    0.004881\n",
       "2001-12-26    0.006369\n",
       "2001-12-27    0.006369\n",
       "2001-12-28    0.004524\n",
       "Name: Close, Length: 372, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AAPL_close = AAPL_close.rolling(3, center=True, min_periods=2).mean()\n",
    "AAPL_close = AAPL_close.diff()[1:]\n",
    "AAPL_close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Use the Iterative Topic Modeling with Time Series Feedback (ITMF) Class\n",
    "### Import Class from Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causal_topic_mining import ITMTF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create object from ITMTF class\n",
    "itmtf = ITMTF(\"./data/nyt_corpus/data/test\", pres_market_forcprob)\n",
    "\n",
    "# Tokenize text corpus and record document timestamps\n",
    "itmtf.build_corpus()\n",
    "\n",
    "# Build vocabulary\n",
    "itmtf.build_vocabulary()\n",
    "\n",
    "# Run ITMTF algorithm\n",
    "itmtf.process(number_of_topics = 30, max_plsa_iter = 1, epsilon = 0.001, mu = 1000, itmtf_iter = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itmtf.average_topic_purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itmtf.average_causality_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
